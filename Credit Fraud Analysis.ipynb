{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.read_csv('credit_train.csv')\n",
    "test_df=pd.read_csv('credit_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.456417</td>\n",
       "      <td>1.327516</td>\n",
       "      <td>-0.635254</td>\n",
       "      <td>-2.765440</td>\n",
       "      <td>0.282230</td>\n",
       "      <td>-0.758234</td>\n",
       "      <td>0.365270</td>\n",
       "      <td>0.927673</td>\n",
       "      <td>0.033947</td>\n",
       "      <td>-1.138995</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.268150</td>\n",
       "      <td>-1.027990</td>\n",
       "      <td>-0.123132</td>\n",
       "      <td>-1.147477</td>\n",
       "      <td>0.058896</td>\n",
       "      <td>0.434728</td>\n",
       "      <td>0.067085</td>\n",
       "      <td>0.072365</td>\n",
       "      <td>4.0</td>\n",
       "      <td>'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.879383</td>\n",
       "      <td>1.138867</td>\n",
       "      <td>0.834804</td>\n",
       "      <td>0.904867</td>\n",
       "      <td>0.164135</td>\n",
       "      <td>-0.486903</td>\n",
       "      <td>0.286551</td>\n",
       "      <td>0.437374</td>\n",
       "      <td>-0.751725</td>\n",
       "      <td>-0.293550</td>\n",
       "      <td>...</td>\n",
       "      <td>0.208368</td>\n",
       "      <td>0.597398</td>\n",
       "      <td>-0.073658</td>\n",
       "      <td>0.098907</td>\n",
       "      <td>-0.232732</td>\n",
       "      <td>-0.289270</td>\n",
       "      <td>0.314182</td>\n",
       "      <td>0.120301</td>\n",
       "      <td>11.8</td>\n",
       "      <td>'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.270210</td>\n",
       "      <td>-0.755504</td>\n",
       "      <td>1.070372</td>\n",
       "      <td>-0.745716</td>\n",
       "      <td>-1.365979</td>\n",
       "      <td>-0.049645</td>\n",
       "      <td>-1.197854</td>\n",
       "      <td>0.207163</td>\n",
       "      <td>-0.677824</td>\n",
       "      <td>0.731290</td>\n",
       "      <td>...</td>\n",
       "      <td>0.475541</td>\n",
       "      <td>1.321484</td>\n",
       "      <td>-0.061854</td>\n",
       "      <td>0.280606</td>\n",
       "      <td>0.297015</td>\n",
       "      <td>-0.050341</td>\n",
       "      <td>0.050163</td>\n",
       "      <td>0.014809</td>\n",
       "      <td>14.0</td>\n",
       "      <td>'0'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.456417  1.327516 -0.635254 -2.765440  0.282230 -0.758234  0.365270   \n",
       "1 -0.879383  1.138867  0.834804  0.904867  0.164135 -0.486903  0.286551   \n",
       "2  1.270210 -0.755504  1.070372 -0.745716 -1.365979 -0.049645 -1.197854   \n",
       "\n",
       "         V8        V9       V10  ...       V21       V22       V23       V24  \\\n",
       "0  0.927673  0.033947 -1.138995  ... -0.268150 -1.027990 -0.123132 -1.147477   \n",
       "1  0.437374 -0.751725 -0.293550  ...  0.208368  0.597398 -0.073658  0.098907   \n",
       "2  0.207163 -0.677824  0.731290  ...  0.475541  1.321484 -0.061854  0.280606   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.058896  0.434728  0.067085  0.072365     4.0    '0'  \n",
       "1 -0.232732 -0.289270  0.314182  0.120301    11.8    '0'  \n",
       "2  0.297015 -0.050341  0.050163  0.014809    14.0    '0'  \n",
       "\n",
       "[3 rows x 30 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size : rows 227845  and columns 30\n",
      "Test size : rows 56962  and columns 30\n"
     ]
    }
   ],
   "source": [
    "print(\"Train size : rows\",train_df.shape[0],\" and columns\",train_df.shape[1])\n",
    "print(\"Test size : rows\",test_df.shape[0],\" and columns\",test_df.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"source\"] = \"train\"\n",
    "test_df[\"source\"] = \"test\"\n",
    "df = pd.concat([train_df,test_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.149913e-15</td>\n",
       "      <td>3.343825e-16</td>\n",
       "      <td>-1.419190e-15</td>\n",
       "      <td>2.073862e-15</td>\n",
       "      <td>9.978906e-16</td>\n",
       "      <td>1.484022e-15</td>\n",
       "      <td>-5.807513e-16</td>\n",
       "      <td>1.046980e-16</td>\n",
       "      <td>-2.403095e-15</td>\n",
       "      <td>2.256948e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>6.499475e-16</td>\n",
       "      <td>1.525166e-16</td>\n",
       "      <td>-3.424988e-16</td>\n",
       "      <td>2.765342e-16</td>\n",
       "      <td>4.491545e-15</td>\n",
       "      <td>5.149942e-16</td>\n",
       "      <td>1.694293e-15</td>\n",
       "      <td>-3.742146e-16</td>\n",
       "      <td>-1.182487e-16</td>\n",
       "      <td>88.349619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>1.088850e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.709250e-01</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>-2.458826e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.449772e+01</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>-5.354257e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.117214e-01</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>-9.291738e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.248109e-02</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>4.539234e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.330408e-01</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>2.374514e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>3.942090e+01</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 V1            V2            V3            V4            V5  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   1.149913e-15  3.343825e-16 -1.419190e-15  2.073862e-15  9.978906e-16   \n",
       "std    1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00  1.380247e+00   \n",
       "min   -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00 -1.137433e+02   \n",
       "25%   -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01 -6.915971e-01   \n",
       "50%    1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02 -5.433583e-02   \n",
       "75%    1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01  6.119264e-01   \n",
       "max    2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01  3.480167e+01   \n",
       "\n",
       "                 V6            V7            V8            V9           V10  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   1.484022e-15 -5.807513e-16  1.046980e-16 -2.403095e-15  2.256948e-15   \n",
       "std    1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00  1.088850e+00   \n",
       "min   -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01 -2.458826e+01   \n",
       "25%   -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01 -5.354257e-01   \n",
       "50%   -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02 -9.291738e-02   \n",
       "75%    3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01  4.539234e-01   \n",
       "max    7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01  2.374514e+01   \n",
       "\n",
       "       ...           V20           V21           V22           V23  \\\n",
       "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   ...  6.499475e-16  1.525166e-16 -3.424988e-16  2.765342e-16   \n",
       "std    ...  7.709250e-01  7.345240e-01  7.257016e-01  6.244603e-01   \n",
       "min    ... -5.449772e+01 -3.483038e+01 -1.093314e+01 -4.480774e+01   \n",
       "25%    ... -2.117214e-01 -2.283949e-01 -5.423504e-01 -1.618463e-01   \n",
       "50%    ... -6.248109e-02 -2.945017e-02  6.781943e-03 -1.119293e-02   \n",
       "75%    ...  1.330408e-01  1.863772e-01  5.285536e-01  1.476421e-01   \n",
       "max    ...  3.942090e+01  2.720284e+01  1.050309e+01  2.252841e+01   \n",
       "\n",
       "                V24           V25           V26           V27           V28  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   4.491545e-15  5.149942e-16  1.694293e-15 -3.742146e-16 -1.182487e-16   \n",
       "std    6.056471e-01  5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01   \n",
       "min   -2.836627e+00 -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01   \n",
       "25%   -3.545861e-01 -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02   \n",
       "50%    4.097606e-02  1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02   \n",
       "75%    4.395266e-01  3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02   \n",
       "max    4.584549e+00  7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   \n",
       "\n",
       "              Amount  \n",
       "count  284807.000000  \n",
       "mean       88.349619  \n",
       "std       250.120109  \n",
       "min         0.000000  \n",
       "25%         5.600000  \n",
       "50%        22.000000  \n",
       "75%        77.165000  \n",
       "max     25691.160000  \n",
       "\n",
       "[8 rows x 29 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Frauds 99.83 % of the dataset\n",
      "Frauds 0.17 % of the dataset\n"
     ]
    }
   ],
   "source": [
    "print('No Frauds', round(df['Class'].value_counts()[0]/len(df) * 100,2), '% of the dataset')\n",
    "print('Frauds', round(df['Class'].value_counts()[1]/len(df) * 100,2), '% of the dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Class Distributions \\n (0: No Fraud || 1: Fraud)')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = [\"#0101DF\", \"#DF0101\"]\n",
    "sns.countplot('Class', data=df, palette=colors)\n",
    "plt.title('Class Distributions \\n (0: No Fraud || 1: Fraud)', fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "\n",
    "# RobustScaler is less prone to outliers.\n",
    "\n",
    "std_scaler = StandardScaler()\n",
    "rob_scaler = RobustScaler()\n",
    "\n",
    "df['scaled_amount'] = rob_scaler.fit_transform(df['Amount'].values.reshape(-1,1))\n",
    "\n",
    "\n",
    "df.drop(['Amount'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scaled_amount</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.251520</td>\n",
       "      <td>-1.456417</td>\n",
       "      <td>1.327516</td>\n",
       "      <td>-0.635254</td>\n",
       "      <td>-2.765440</td>\n",
       "      <td>0.282230</td>\n",
       "      <td>-0.758234</td>\n",
       "      <td>0.365270</td>\n",
       "      <td>0.927673</td>\n",
       "      <td>0.033947</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.268150</td>\n",
       "      <td>-1.027990</td>\n",
       "      <td>-0.123132</td>\n",
       "      <td>-1.147477</td>\n",
       "      <td>0.058896</td>\n",
       "      <td>0.434728</td>\n",
       "      <td>0.067085</td>\n",
       "      <td>0.072365</td>\n",
       "      <td>'0'</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.142528</td>\n",
       "      <td>-0.879383</td>\n",
       "      <td>1.138867</td>\n",
       "      <td>0.834804</td>\n",
       "      <td>0.904867</td>\n",
       "      <td>0.164135</td>\n",
       "      <td>-0.486903</td>\n",
       "      <td>0.286551</td>\n",
       "      <td>0.437374</td>\n",
       "      <td>-0.751725</td>\n",
       "      <td>...</td>\n",
       "      <td>0.208368</td>\n",
       "      <td>0.597398</td>\n",
       "      <td>-0.073658</td>\n",
       "      <td>0.098907</td>\n",
       "      <td>-0.232732</td>\n",
       "      <td>-0.289270</td>\n",
       "      <td>0.314182</td>\n",
       "      <td>0.120301</td>\n",
       "      <td>'0'</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.111786</td>\n",
       "      <td>1.270210</td>\n",
       "      <td>-0.755504</td>\n",
       "      <td>1.070372</td>\n",
       "      <td>-0.745716</td>\n",
       "      <td>-1.365979</td>\n",
       "      <td>-0.049645</td>\n",
       "      <td>-1.197854</td>\n",
       "      <td>0.207163</td>\n",
       "      <td>-0.677824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.475541</td>\n",
       "      <td>1.321484</td>\n",
       "      <td>-0.061854</td>\n",
       "      <td>0.280606</td>\n",
       "      <td>0.297015</td>\n",
       "      <td>-0.050341</td>\n",
       "      <td>0.050163</td>\n",
       "      <td>0.014809</td>\n",
       "      <td>'0'</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.139733</td>\n",
       "      <td>1.967062</td>\n",
       "      <td>0.445029</td>\n",
       "      <td>-2.472415</td>\n",
       "      <td>1.290097</td>\n",
       "      <td>1.284233</td>\n",
       "      <td>-0.398478</td>\n",
       "      <td>0.641294</td>\n",
       "      <td>-0.209637</td>\n",
       "      <td>-0.219990</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011025</td>\n",
       "      <td>0.184953</td>\n",
       "      <td>-0.079679</td>\n",
       "      <td>0.188458</td>\n",
       "      <td>0.516061</td>\n",
       "      <td>-0.521453</td>\n",
       "      <td>-0.005402</td>\n",
       "      <td>-0.030380</td>\n",
       "      <td>'0'</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.599455</td>\n",
       "      <td>-0.626555</td>\n",
       "      <td>1.218109</td>\n",
       "      <td>0.871426</td>\n",
       "      <td>0.950972</td>\n",
       "      <td>-0.311923</td>\n",
       "      <td>-0.711223</td>\n",
       "      <td>0.686529</td>\n",
       "      <td>0.214618</td>\n",
       "      <td>-0.916320</td>\n",
       "      <td>...</td>\n",
       "      <td>0.237543</td>\n",
       "      <td>0.529095</td>\n",
       "      <td>0.015473</td>\n",
       "      <td>0.401008</td>\n",
       "      <td>-0.195985</td>\n",
       "      <td>-0.335558</td>\n",
       "      <td>0.031509</td>\n",
       "      <td>0.106962</td>\n",
       "      <td>'0'</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   scaled_amount        V1        V2        V3        V4        V5        V6  \\\n",
       "0      -0.251520 -1.456417  1.327516 -0.635254 -2.765440  0.282230 -0.758234   \n",
       "1      -0.142528 -0.879383  1.138867  0.834804  0.904867  0.164135 -0.486903   \n",
       "2      -0.111786  1.270210 -0.755504  1.070372 -0.745716 -1.365979 -0.049645   \n",
       "3       0.139733  1.967062  0.445029 -2.472415  1.290097  1.284233 -0.398478   \n",
       "4       0.599455 -0.626555  1.218109  0.871426  0.950972 -0.311923 -0.711223   \n",
       "\n",
       "         V7        V8        V9  ...       V21       V22       V23       V24  \\\n",
       "0  0.365270  0.927673  0.033947  ... -0.268150 -1.027990 -0.123132 -1.147477   \n",
       "1  0.286551  0.437374 -0.751725  ...  0.208368  0.597398 -0.073658  0.098907   \n",
       "2 -1.197854  0.207163 -0.677824  ...  0.475541  1.321484 -0.061854  0.280606   \n",
       "3  0.641294 -0.209637 -0.219990  ...  0.011025  0.184953 -0.079679  0.188458   \n",
       "4  0.686529  0.214618 -0.916320  ...  0.237543  0.529095  0.015473  0.401008   \n",
       "\n",
       "        V25       V26       V27       V28  Class  source  \n",
       "0  0.058896  0.434728  0.067085  0.072365    '0'   train  \n",
       "1 -0.232732 -0.289270  0.314182  0.120301    '0'   train  \n",
       "2  0.297015 -0.050341  0.050163  0.014809    '0'   train  \n",
       "3  0.516061 -0.521453 -0.005402 -0.030380    '0'   train  \n",
       "4 -0.195985 -0.335558  0.031509  0.106962    '0'   train  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_amount = df['scaled_amount']\n",
    "\n",
    "\n",
    "df.drop(['scaled_amount'], axis=1, inplace=True)\n",
    "df.insert(0, 'scaled_amount', scaled_amount)\n",
    "\n",
    "# Amount is Scaled!\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Frauds 99.83 % of the dataset\n",
      "Frauds 0.17 % of the dataset\n",
      "Train: [ 52773  52971  52994 ... 284804 284805 284806] Test: [    0     1     2 ... 56971 56972 56973]\n",
      "Train: [     0      1      2 ... 284804 284805 284806] Test: [ 52773  52971  52994 ... 113935 113936 113937]\n",
      "Train: [     0      1      2 ... 284804 284805 284806] Test: [106947 107307 107384 ... 170887 170888 170889]\n",
      "Train: [     0      1      2 ... 284804 284805 284806] Test: [168824 168871 169872 ... 228361 228455 229223]\n",
      "Train: [     0      1      2 ... 228361 228455 229223] Test: [227841 227842 227844 ... 284804 284805 284806]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Label Distributions: \n",
      "\n",
      "[0.99827076 0.00172924]\n",
      "[0.99827952 0.00172048]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "print('No Frauds', round(df['Class'].value_counts()[0]/len(df) * 100,2), '% of the dataset')\n",
    "print('Frauds', round(df['Class'].value_counts()[1]/len(df) * 100,2), '% of the dataset')\n",
    "\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n",
    "\n",
    "sss = StratifiedKFold(n_splits=5, random_state=None, shuffle=False)\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    print(\"Train:\", train_index, \"Test:\", test_index)\n",
    "    original_Xtrain, original_Xtest = X.iloc[train_index], X.iloc[test_index]\n",
    "    original_ytrain, original_ytest = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "# We already have X_train and y_train for undersample data thats why I am using original to distinguish and to not overwrite these variables.\n",
    "# original_Xtrain, original_Xtest, original_ytrain, original_ytest = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check the Distribution of the labels\n",
    "\n",
    "\n",
    "# Turn into an array\n",
    "original_Xtrain = original_Xtrain.values\n",
    "original_Xtest = original_Xtest.values\n",
    "original_ytrain = original_ytrain.values\n",
    "original_ytest = original_ytest.values\n",
    "# See if both the train and test label distribution are similarly distributed\n",
    "train_unique_label, train_counts_label = np.unique(original_ytrain, return_counts=True)\n",
    "test_unique_label, test_counts_label = np.unique(original_ytest, return_counts=True)\n",
    "print('-' * 100)\n",
    "\n",
    "print('Label Distributions: \\n')\n",
    "print(train_counts_label/ len(original_ytrain))\n",
    "print(test_counts_label/ len(original_ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Class'] = df['Class'].str.replace(\"'\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scaled_amount</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>178139</th>\n",
       "      <td>0.160274</td>\n",
       "      <td>-0.795638</td>\n",
       "      <td>2.023346</td>\n",
       "      <td>-1.123996</td>\n",
       "      <td>0.708170</td>\n",
       "      <td>0.549575</td>\n",
       "      <td>1.429078</td>\n",
       "      <td>-1.723821</td>\n",
       "      <td>-5.738158</td>\n",
       "      <td>-0.615502</td>\n",
       "      <td>...</td>\n",
       "      <td>1.663083</td>\n",
       "      <td>-1.014281</td>\n",
       "      <td>0.084660</td>\n",
       "      <td>-1.554576</td>\n",
       "      <td>0.952460</td>\n",
       "      <td>-0.159066</td>\n",
       "      <td>0.291875</td>\n",
       "      <td>0.287179</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148191</th>\n",
       "      <td>-0.159435</td>\n",
       "      <td>-0.959156</td>\n",
       "      <td>1.961947</td>\n",
       "      <td>-1.425879</td>\n",
       "      <td>-0.199841</td>\n",
       "      <td>-0.040009</td>\n",
       "      <td>-1.436193</td>\n",
       "      <td>0.304802</td>\n",
       "      <td>0.607620</td>\n",
       "      <td>0.020472</td>\n",
       "      <td>...</td>\n",
       "      <td>0.289537</td>\n",
       "      <td>0.985329</td>\n",
       "      <td>-0.075484</td>\n",
       "      <td>-0.081633</td>\n",
       "      <td>-0.184852</td>\n",
       "      <td>-0.122661</td>\n",
       "      <td>0.359797</td>\n",
       "      <td>0.182852</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191749</th>\n",
       "      <td>-0.279746</td>\n",
       "      <td>1.201135</td>\n",
       "      <td>0.057694</td>\n",
       "      <td>0.577186</td>\n",
       "      <td>0.572928</td>\n",
       "      <td>-0.703247</td>\n",
       "      <td>-0.833298</td>\n",
       "      <td>-0.173894</td>\n",
       "      <td>0.043467</td>\n",
       "      <td>0.078150</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.215490</td>\n",
       "      <td>-0.760369</td>\n",
       "      <td>0.173452</td>\n",
       "      <td>0.474882</td>\n",
       "      <td>0.091441</td>\n",
       "      <td>0.071236</td>\n",
       "      <td>-0.045890</td>\n",
       "      <td>0.006594</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1485</th>\n",
       "      <td>0.041920</td>\n",
       "      <td>1.354196</td>\n",
       "      <td>-0.615297</td>\n",
       "      <td>0.424670</td>\n",
       "      <td>-0.832530</td>\n",
       "      <td>-1.005418</td>\n",
       "      <td>-0.539372</td>\n",
       "      <td>-0.705519</td>\n",
       "      <td>0.026451</td>\n",
       "      <td>-0.857378</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.068262</td>\n",
       "      <td>-0.431772</td>\n",
       "      <td>0.078890</td>\n",
       "      <td>-0.035418</td>\n",
       "      <td>0.207750</td>\n",
       "      <td>-0.475794</td>\n",
       "      <td>-0.002927</td>\n",
       "      <td>0.009990</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206121</th>\n",
       "      <td>0.109690</td>\n",
       "      <td>-0.298761</td>\n",
       "      <td>0.921749</td>\n",
       "      <td>-0.165774</td>\n",
       "      <td>-0.460667</td>\n",
       "      <td>0.040680</td>\n",
       "      <td>-0.186185</td>\n",
       "      <td>-0.031449</td>\n",
       "      <td>0.543738</td>\n",
       "      <td>0.426889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.222933</td>\n",
       "      <td>0.767480</td>\n",
       "      <td>0.032529</td>\n",
       "      <td>0.434826</td>\n",
       "      <td>-0.627750</td>\n",
       "      <td>0.484521</td>\n",
       "      <td>0.232913</td>\n",
       "      <td>0.137498</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        scaled_amount        V1        V2        V3        V4        V5  \\\n",
       "178139       0.160274 -0.795638  2.023346 -1.123996  0.708170  0.549575   \n",
       "148191      -0.159435 -0.959156  1.961947 -1.425879 -0.199841 -0.040009   \n",
       "191749      -0.279746  1.201135  0.057694  0.577186  0.572928 -0.703247   \n",
       "1485         0.041920  1.354196 -0.615297  0.424670 -0.832530 -1.005418   \n",
       "206121       0.109690 -0.298761  0.921749 -0.165774 -0.460667  0.040680   \n",
       "\n",
       "              V6        V7        V8        V9  ...       V21       V22  \\\n",
       "178139  1.429078 -1.723821 -5.738158 -0.615502  ...  1.663083 -1.014281   \n",
       "148191 -1.436193  0.304802  0.607620  0.020472  ...  0.289537  0.985329   \n",
       "191749 -0.833298 -0.173894  0.043467  0.078150  ... -0.215490 -0.760369   \n",
       "1485   -0.539372 -0.705519  0.026451 -0.857378  ... -0.068262 -0.431772   \n",
       "206121 -0.186185 -0.031449  0.543738  0.426889  ...  0.222933  0.767480   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  Class  \\\n",
       "178139  0.084660 -1.554576  0.952460 -0.159066  0.291875  0.287179      0   \n",
       "148191 -0.075484 -0.081633 -0.184852 -0.122661  0.359797  0.182852      0   \n",
       "191749  0.173452  0.474882  0.091441  0.071236 -0.045890  0.006594      0   \n",
       "1485    0.078890 -0.035418  0.207750 -0.475794 -0.002927  0.009990      0   \n",
       "206121  0.032529  0.434826 -0.627750  0.484521  0.232913  0.137498      0   \n",
       "\n",
       "        source  \n",
       "178139   train  \n",
       "148191   train  \n",
       "191749   train  \n",
       "1485      test  \n",
       "206121   train  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(frac=1)\n",
    "\n",
    "# amount of fraud classes 492 rows.\n",
    "fraud_df = df.loc[df['Class'] == 1]\n",
    "non_fraud_df = df.loc[df['Class'] == 0][:492]\n",
    "\n",
    "normal_distributed_df = pd.concat([fraud_df, non_fraud_df])\n",
    "\n",
    "# Shuffle dataframe rows\n",
    "new_df = normal_distributed_df.sample(frac=1, random_state=42)\n",
    "new_df = df\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scaled_amount</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>178139</th>\n",
       "      <td>0.160274</td>\n",
       "      <td>-0.795638</td>\n",
       "      <td>2.023346</td>\n",
       "      <td>-1.123996</td>\n",
       "      <td>0.708170</td>\n",
       "      <td>0.549575</td>\n",
       "      <td>1.429078</td>\n",
       "      <td>-1.723821</td>\n",
       "      <td>-5.738158</td>\n",
       "      <td>-0.615502</td>\n",
       "      <td>...</td>\n",
       "      <td>1.663083</td>\n",
       "      <td>-1.014281</td>\n",
       "      <td>0.084660</td>\n",
       "      <td>-1.554576</td>\n",
       "      <td>0.952460</td>\n",
       "      <td>-0.159066</td>\n",
       "      <td>0.291875</td>\n",
       "      <td>0.287179</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148191</th>\n",
       "      <td>-0.159435</td>\n",
       "      <td>-0.959156</td>\n",
       "      <td>1.961947</td>\n",
       "      <td>-1.425879</td>\n",
       "      <td>-0.199841</td>\n",
       "      <td>-0.040009</td>\n",
       "      <td>-1.436193</td>\n",
       "      <td>0.304802</td>\n",
       "      <td>0.607620</td>\n",
       "      <td>0.020472</td>\n",
       "      <td>...</td>\n",
       "      <td>0.289537</td>\n",
       "      <td>0.985329</td>\n",
       "      <td>-0.075484</td>\n",
       "      <td>-0.081633</td>\n",
       "      <td>-0.184852</td>\n",
       "      <td>-0.122661</td>\n",
       "      <td>0.359797</td>\n",
       "      <td>0.182852</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191749</th>\n",
       "      <td>-0.279746</td>\n",
       "      <td>1.201135</td>\n",
       "      <td>0.057694</td>\n",
       "      <td>0.577186</td>\n",
       "      <td>0.572928</td>\n",
       "      <td>-0.703247</td>\n",
       "      <td>-0.833298</td>\n",
       "      <td>-0.173894</td>\n",
       "      <td>0.043467</td>\n",
       "      <td>0.078150</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.215490</td>\n",
       "      <td>-0.760369</td>\n",
       "      <td>0.173452</td>\n",
       "      <td>0.474882</td>\n",
       "      <td>0.091441</td>\n",
       "      <td>0.071236</td>\n",
       "      <td>-0.045890</td>\n",
       "      <td>0.006594</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1485</th>\n",
       "      <td>0.041920</td>\n",
       "      <td>1.354196</td>\n",
       "      <td>-0.615297</td>\n",
       "      <td>0.424670</td>\n",
       "      <td>-0.832530</td>\n",
       "      <td>-1.005418</td>\n",
       "      <td>-0.539372</td>\n",
       "      <td>-0.705519</td>\n",
       "      <td>0.026451</td>\n",
       "      <td>-0.857378</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.068262</td>\n",
       "      <td>-0.431772</td>\n",
       "      <td>0.078890</td>\n",
       "      <td>-0.035418</td>\n",
       "      <td>0.207750</td>\n",
       "      <td>-0.475794</td>\n",
       "      <td>-0.002927</td>\n",
       "      <td>0.009990</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206121</th>\n",
       "      <td>0.109690</td>\n",
       "      <td>-0.298761</td>\n",
       "      <td>0.921749</td>\n",
       "      <td>-0.165774</td>\n",
       "      <td>-0.460667</td>\n",
       "      <td>0.040680</td>\n",
       "      <td>-0.186185</td>\n",
       "      <td>-0.031449</td>\n",
       "      <td>0.543738</td>\n",
       "      <td>0.426889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.222933</td>\n",
       "      <td>0.767480</td>\n",
       "      <td>0.032529</td>\n",
       "      <td>0.434826</td>\n",
       "      <td>-0.627750</td>\n",
       "      <td>0.484521</td>\n",
       "      <td>0.232913</td>\n",
       "      <td>0.137498</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        scaled_amount        V1        V2        V3        V4        V5  \\\n",
       "178139       0.160274 -0.795638  2.023346 -1.123996  0.708170  0.549575   \n",
       "148191      -0.159435 -0.959156  1.961947 -1.425879 -0.199841 -0.040009   \n",
       "191749      -0.279746  1.201135  0.057694  0.577186  0.572928 -0.703247   \n",
       "1485         0.041920  1.354196 -0.615297  0.424670 -0.832530 -1.005418   \n",
       "206121       0.109690 -0.298761  0.921749 -0.165774 -0.460667  0.040680   \n",
       "\n",
       "              V6        V7        V8        V9  ...       V21       V22  \\\n",
       "178139  1.429078 -1.723821 -5.738158 -0.615502  ...  1.663083 -1.014281   \n",
       "148191 -1.436193  0.304802  0.607620  0.020472  ...  0.289537  0.985329   \n",
       "191749 -0.833298 -0.173894  0.043467  0.078150  ... -0.215490 -0.760369   \n",
       "1485   -0.539372 -0.705519  0.026451 -0.857378  ... -0.068262 -0.431772   \n",
       "206121 -0.186185 -0.031449  0.543738  0.426889  ...  0.222933  0.767480   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  Class  \\\n",
       "178139  0.084660 -1.554576  0.952460 -0.159066  0.291875  0.287179      0   \n",
       "148191 -0.075484 -0.081633 -0.184852 -0.122661  0.359797  0.182852      0   \n",
       "191749  0.173452  0.474882  0.091441  0.071236 -0.045890  0.006594      0   \n",
       "1485    0.078890 -0.035418  0.207750 -0.475794 -0.002927  0.009990      0   \n",
       "206121  0.032529  0.434826 -0.627750  0.484521  0.232913  0.137498      0   \n",
       "\n",
       "        source  \n",
       "178139   train  \n",
       "148191   train  \n",
       "191749   train  \n",
       "1485      test  \n",
       "206121   train  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_df = df.loc[df['Class'] == 1]\n",
    "non_fraud_df = df.loc[df['Class'] == 0][:492]\n",
    "normal_distributed_df = pd.concat([fraud_df, non_fraud_df])\n",
    "new_df = normal_distributed_df.sample(frac=1, random_state=42)\n",
    "new_df=df\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of the Classes in the subsample dataset\n",
      "0    0.998273\n",
      "1    0.001727\n",
      "Name: Class, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Distribution of the Classes in the subsample dataset')\n",
    "print(new_df['Class'].value_counts()/len(new_df))\n",
    "\n",
    "\n",
    "\n",
    "sns.countplot('Class', data=new_df, palette=colors)\n",
    "plt.title('Equally Distributed Classes', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_df.drop(['Class','source'], axis=1)\n",
    "y = new_df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# This is explicitly used for undersampling.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "y_train = y_train.values\n",
    "y_test = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import collections\n",
    "\n",
    "classifiers = {\n",
    "    \"LogisiticRegression\": LogisticRegression(),\n",
    "    \"KNearest\": KNeighborsClassifier(),\n",
    "    \"Support Vector Classifier\": SVC(),\n",
    "    \"DecisionTreeClassifier\": DecisionTreeClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhuji\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\bhuji\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\bhuji\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\bhuji\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\bhuji\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\bhuji\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifiers:  LogisticRegression Has a training score of 100.0 % accuracy score\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "for key, classifier in classifiers.items():\n",
    "    classifier.fit(X_train, y_train)\n",
    "    training_score = cross_val_score(classifier, X_train, y_train, cv=5)\n",
    "    print(\"Classifiers: \", classifier.__class__.__name__, \"Has a training score of\", round(training_score.mean(), 2) * 100, \"% accuracy score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# Logistic Regression \n",
    "log_reg_params = {\"penalty\": ['l1', 'l2'], 'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "\n",
    "\n",
    "\n",
    "grid_log_reg = GridSearchCV(LogisticRegression(), log_reg_params)\n",
    "grid_log_reg.fit(X_train, y_train)\n",
    "# We automatically get the logistic regression with the best parameters.\n",
    "log_reg = grid_log_reg.best_estimator_\n",
    "\n",
    "knears_params = {\"n_neighbors\": list(range(2,5,1)), 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']}\n",
    "grid_knears = GridSearchCV(KNeighborsClassifier(), knears_params)\n",
    "grid_knears.fit(X_train, y_train)\n",
    "# KNears best estimator\n",
    "knears_neighbors = grid_knears.best_estimator_\n",
    "\n",
    "# Support Vector Classifier\n",
    "svc_params = {'C': [0.5, 0.7, 0.9, 1], 'kernel': ['rbf', 'poly', 'sigmoid', 'linear']}\n",
    "grid_svc = GridSearchCV(SVC(), svc_params)\n",
    "grid_svc.fit(X_train, y_train)\n",
    "\n",
    "# SVC best estimator\n",
    "svc = grid_svc.best_estimator_\n",
    "\n",
    "# DecisionTree Classifier\n",
    "tree_params = {\"criterion\": [\"gini\", \"entropy\"], \"max_depth\": list(range(2,4,1)), \n",
    "              \"min_samples_leaf\": list(range(5,7,1))}\n",
    "grid_tree = GridSearchCV(DecisionTreeClassifier(), tree_params)\n",
    "grid_tree.fit(X_train, y_train)\n",
    "tree_clf = grid_tree.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "\n",
    "\n",
    "print('Length of X (train): {} | Length of y (train): {}'.format(len(original_Xtrain), len(original_ytrain)))\n",
    "print('Length of X (test): {} | Length of y (test): {}'.format(len(original_Xtest), len(original_ytest)))\n",
    "\n",
    "# List to append the score and then find the average\n",
    "accuracy_lst = []\n",
    "precision_lst = []\n",
    "recall_lst = []\n",
    "f1_lst = []\n",
    "auc_lst = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_sm = LogisticRegression()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "rand_log_reg = RandomizedSearchCV(LogisticRegression(), log_reg_params, n_iter=4)\n",
    "\n",
    "\n",
    "# Implementing SMOTE Technique \n",
    "# Cross Validating the right way\n",
    "# Parameters\n",
    "log_reg_params = {\"penalty\": ['l1', 'l2'], 'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "for train, test in sss.split(original_Xtrain, original_ytrain):\n",
    "    pipeline = imbalanced_make_pipeline(SMOTE(sampling_strategy='minority'), rand_log_reg) # SMOTE happens during Cross Validation not before..\n",
    "    model = pipeline.fit(original_Xtrain[train], original_ytrain[train])\n",
    "    best_est = rand_log_reg.best_estimator_\n",
    "    prediction = best_est.predict(original_Xtrain[test])\n",
    "    \n",
    "      accuracy_lst.append(pipeline.score(original_Xtrain[test], original_ytrain[test]))\n",
    "    precision_lst.append(precision_score(original_ytrain[test], prediction))\n",
    "    recall_lst.append(recall_score(original_ytrain[test], prediction))\n",
    "    f1_lst.append(f1_score(original_ytrain[test], prediction))\n",
    "    auc_lst.append(roc_auc_score(original_ytrain[test], prediction))\n",
    "    \n",
    "print('---' * 45)\n",
    "print('')\n",
    "print(\"accuracy: {}\".format(np.mean(accuracy_lst)))\n",
    "print(\"precision: {}\".format(np.mean(precision_lst)))\n",
    "print(\"recall: {}\".format(np.mean(recall_lst)))\n",
    "print(\"f1: {}\".format(np.mean(f1_lst)))\n",
    "print('---' * 45)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
