{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SentimentAnalysis.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhujithk/mlCodeSnippets/blob/master/SentimentAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-mP4JbXDS3P",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "c983c4c0-42c9-4d06-c9a2-fd6d8b37277a"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-bbd56f85-51c9-45d5-953b-80d522189581\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-bbd56f85-51c9-45d5-953b-80d522189581\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving review_test.csv to review_test.csv\n",
            "Saving review_train.csv to review_train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ON_XysKREtxH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "68b1eb99-0106-4358-fa78-5a3c83d39867"
      },
      "source": [
        "!pip install contractions\n",
        "!pip install textsearch\n",
        "!pip install tqdm"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting contractions\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/2a/ba0a3812e2a1de2cc4ee0ded0bdb750a7cef1631c13c78a4fc4ab042adec/contractions-0.0.21-py2.py3-none-any.whl\n",
            "Installing collected packages: contractions\n",
            "Successfully installed contractions-0.0.21\n",
            "Collecting textsearch\n",
            "  Downloading https://files.pythonhosted.org/packages/42/a8/03407021f9555043de5492a2bd7a35c56cc03c2510092b5ec018cae1bbf1/textsearch-0.0.17-py2.py3-none-any.whl\n",
            "Collecting Unidecode (from textsearch)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 6.8MB/s \n",
            "\u001b[?25hCollecting pyahocorasick (from textsearch)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/9f/f0d8e8850e12829eea2e778f1c90e3c53a9a799b7f412082a5d21cd19ae1/pyahocorasick-1.4.0.tar.gz (312kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 43.9MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyahocorasick\n",
            "  Building wheel for pyahocorasick (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyahocorasick: filename=pyahocorasick-1.4.0-cp36-cp36m-linux_x86_64.whl size=81706 sha256=be51633113aea301bffc6eb86f7c8dc8a6d61b1b838c7c89cbe27538852b3792\n",
            "  Stored in directory: /root/.cache/pip/wheels/0a/90/61/87a55f5b459792fbb2b7ba6b31721b06ff5cf6bde541b40994\n",
            "Successfully built pyahocorasick\n",
            "Installing collected packages: Unidecode, pyahocorasick, textsearch\n",
            "Successfully installed Unidecode-1.1.1 pyahocorasick-1.4.0 textsearch-0.0.17\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.28.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyh1BR2dE0GC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "a8055a12-f187-4681-94c2-8f5092df0561"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import pandas as pd\n",
        "\n",
        "dataset = pd.read_csv(r'review_train.csv')\n",
        "dataset.info()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 14825 entries, 0 to 14824\n",
            "Data columns (total 3 columns):\n",
            "Text         14825 non-null object\n",
            "Score        14825 non-null int64\n",
            "Sentiment    14825 non-null int64\n",
            "dtypes: int64(2), object(1)\n",
            "memory usage: 347.5+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uxp8oMX5E70M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "ee6521d6-8038-4780-cd5c-4a7ac9239845"
      },
      "source": [
        "dataset.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Score</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I got a free sample of these once, and now--we...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I used to get this Tea when I lived in Washing...</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>This is my all time favorite 'grab and go' sna...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>This flavor is very good and unexpected.  The ...</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>thrilled to have this assortment as i got the ...</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text  Score  Sentiment\n",
              "0  I got a free sample of these once, and now--we...      5          1\n",
              "1  I used to get this Tea when I lived in Washing...      4          1\n",
              "2  This is my all time favorite 'grab and go' sna...      5          1\n",
              "3  This flavor is very good and unexpected.  The ...      4          1\n",
              "4  thrilled to have this assortment as i got the ...      4          1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGqlT3fOFCOD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "9109de18-7d2f-47d1-92ed-7a3b222c035e"
      },
      "source": [
        "dataset_test = pd.read_csv(r'review_test.csv')\n",
        "dataset_test.info()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3707 entries, 0 to 3706\n",
            "Data columns (total 3 columns):\n",
            "Text         3707 non-null object\n",
            "Score        3707 non-null int64\n",
            "Sentiment    3707 non-null int64\n",
            "dtypes: int64(2), object(1)\n",
            "memory usage: 87.0+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOD4w2f5FHQZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_reviews = dataset['Text'].values\n",
        "train_sentiments = dataset['Sentiment'].values\n",
        "\n",
        "test_reviews = dataset_test['Text'].values \n",
        "test_sentiments = dataset_test['Sentiment'].values "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dleGmJBnFL7E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import contractions\n",
        "from bs4 import BeautifulSoup\n",
        "import numpy as np\n",
        "import re\n",
        "import tqdm\n",
        "import unicodedata\n",
        "\n",
        "\n",
        "def strip_html_tags(text):\n",
        "  soup = BeautifulSoup(text, \"html.parser\")\n",
        "  [s.extract() for s in soup(['iframe', 'script'])]\n",
        "  stripped_text = soup.get_text()\n",
        "  stripped_text = re.sub(r'[\\r|\\n|\\r\\n]+', '\\n', stripped_text)\n",
        "  return stripped_text\n",
        "\n",
        "def remove_accented_chars(text):\n",
        "  text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "  return text\n",
        "\n",
        "def pre_process_corpus(docs):\n",
        "  norm_docs = []\n",
        "  for doc in tqdm.tqdm(docs):\n",
        "    doc = strip_html_tags(doc)\n",
        "    doc = doc.translate(doc.maketrans(\"\\n\\t\\r\", \"   \"))\n",
        "    doc = doc.lower()\n",
        "    doc = remove_accented_chars(doc)\n",
        "    doc = contractions.fix(doc)\n",
        "    # lower case and remove special characters\\whitespaces\n",
        "    doc = re.sub(r'[^a-zA-Z0-9\\s]', '', doc, re.I|re.A)\n",
        "    doc = re.sub(' +', ' ', doc)\n",
        "    doc = doc.strip()  \n",
        "    norm_docs.append(doc)\n",
        "  return norm_docs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwKD4z4MFXzd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "702151e6-f8a3-4f2c-da19-088d48be5175"
      },
      "source": [
        "%%time\n",
        "\n",
        "norm_train_reviews = pre_process_corpus(train_reviews)\n",
        "norm_test_reviews = pre_process_corpus(test_reviews)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14825/14825 [00:03<00:00, 4491.10it/s]\n",
            "100%|██████████| 3707/3707 [00:00<00:00, 4548.44it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3.96 s, sys: 110 ms, total: 4.07 s\n",
            "Wall time: 4.12 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2K9F0LyjFmXo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "70af3f56-b9a4-4c76-8654-48bf5a69b123"
      },
      "source": [
        "%%time\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "# build BOW features on train reviews\n",
        "cv = CountVectorizer(binary=False, min_df=5, max_df=1.0, ngram_range=(1,2))\n",
        "cv_train_features = cv.fit_transform(norm_train_reviews)\n",
        "\n",
        "\n",
        "# build TFIDF features on train reviews\n",
        "tv = TfidfVectorizer(use_idf=True, min_df=5, max_df=1.0, ngram_range=(1,2),\n",
        "                     sublinear_tf=True)\n",
        "tv_train_features = tv.fit_transform(norm_train_reviews)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 6.4 s, sys: 208 ms, total: 6.61 s\n",
            "Wall time: 6.64 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RYjOZAPFusM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "cb7d828a-4ca1-4e62-97d2-dce338fac2f9"
      },
      "source": [
        "%%time\n",
        "\n",
        "# transform test reviews into features\n",
        "cv_test_features = cv.transform(norm_test_reviews)\n",
        "tv_test_features = tv.transform(norm_test_reviews)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1.05 s, sys: 6.72 ms, total: 1.06 s\n",
            "Wall time: 1.07 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Crb9F-sVF2jc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "eb8e117d-4a43-488f-fe11-bfe51e3ec0f9"
      },
      "source": [
        "print('BOW model:> Train features shape:', cv_train_features.shape, ' Test features shape:', cv_test_features.shape)\n",
        "print('TFIDF model:> Train features shape:', tv_train_features.shape, ' Test features shape:', tv_test_features.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BOW model:> Train features shape: (14825, 36702)  Test features shape: (3707, 36702)\n",
            "TFIDF model:> Train features shape: (14825, 36702)  Test features shape: (3707, 36702)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0X0WKR8gGBJL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e1b843c0-0cf5-4c13-9dbd-955ce899be63"
      },
      "source": [
        "%%time\n",
        "\n",
        "# Logistic Regression model on BOW features\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# instantiate model\n",
        "lr = LogisticRegression(penalty='l2', max_iter=500, C=1, solver='lbfgs', random_state=42)\n",
        "\n",
        "# train model\n",
        "lr.fit(cv_train_features, train_sentiments)\n",
        "\n",
        "# predict on test data\n",
        "lr_bow_predictions = lr.predict(cv_test_features)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 4.02 s, sys: 2.61 s, total: 6.63 s\n",
            "Wall time: 3.4 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ezrwd9KlGEYJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "outputId": "4bed2d40-4388-4356-e6c6-aa52bc67072a"
      },
      "source": [
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "labels = ['negative', 'positive']\n",
        "print(classification_report(test_sentiments, lr_bow_predictions))\n",
        "pd.DataFrame(confusion_matrix(test_sentiments, lr_bow_predictions), index=labels, columns=labels)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.68      0.75       592\n",
            "           1       0.94      0.97      0.96      3115\n",
            "\n",
            "    accuracy                           0.93      3707\n",
            "   macro avg       0.89      0.83      0.85      3707\n",
            "weighted avg       0.92      0.93      0.92      3707\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>negative</th>\n",
              "      <th>positive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>negative</th>\n",
              "      <td>404</td>\n",
              "      <td>188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>positive</th>\n",
              "      <td>79</td>\n",
              "      <td>3036</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          negative  positive\n",
              "negative       404       188\n",
              "positive        79      3036"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OXAbi7tGIj3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4c308698-96b6-44a1-ba95-d9dee4dbcce3"
      },
      "source": [
        "\n",
        "%%time\n",
        "\n",
        "# Logistic Regression model on TF-IDF features\n",
        "\n",
        "# train model\n",
        "lr.fit(tv_train_features, train_sentiments)\n",
        "\n",
        "# predict on test data\n",
        "lr_tfidf_predictions = lr.predict(tv_test_features)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 907 ms, sys: 603 ms, total: 1.51 s\n",
            "Wall time: 784 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19W8-0ypGM0F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "outputId": "b00b4642-a0f0-4bd5-8594-36c4d8215928"
      },
      "source": [
        "labels = ['negative', 'positive']\n",
        "print(classification_report(test_sentiments, lr_tfidf_predictions))\n",
        "pd.DataFrame(confusion_matrix(test_sentiments, lr_tfidf_predictions), index=labels, columns=labels)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.41      0.57       592\n",
            "           1       0.90      1.00      0.94      3115\n",
            "\n",
            "    accuracy                           0.90      3707\n",
            "   macro avg       0.93      0.70      0.76      3707\n",
            "weighted avg       0.91      0.90      0.89      3707\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>negative</th>\n",
              "      <th>positive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>negative</th>\n",
              "      <td>242</td>\n",
              "      <td>350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>positive</th>\n",
              "      <td>12</td>\n",
              "      <td>3103</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          negative  positive\n",
              "negative       242       350\n",
              "positive        12      3103"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWg84LdoGSG4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9faa1993-7f3a-4ec1-fdf0-be663a4dbc59"
      },
      "source": [
        "%%time\n",
        "\n",
        "# Random Forest model on BOW features\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# instantiate model\n",
        "rf = RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=42)\n",
        "\n",
        "# train model\n",
        "rf.fit(cv_train_features, train_sentiments)\n",
        "\n",
        "# predict on test data\n",
        "rf_bow_predictions = rf.predict(cv_test_features)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 24.3 s, sys: 45.6 ms, total: 24.3 s\n",
            "Wall time: 12.6 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEmdsAo8GYFJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "outputId": "a56a64cd-39d6-42e4-946b-ca93801802e3"
      },
      "source": [
        "labels = ['negative', 'positive']\n",
        "print(classification_report(test_sentiments, rf_bow_predictions))\n",
        "pd.DataFrame(confusion_matrix(test_sentiments, rf_bow_predictions), index=labels, columns=labels)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.17      0.29       592\n",
            "           1       0.86      1.00      0.93      3115\n",
            "\n",
            "    accuracy                           0.87      3707\n",
            "   macro avg       0.93      0.59      0.61      3707\n",
            "weighted avg       0.88      0.87      0.83      3707\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>negative</th>\n",
              "      <th>positive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>negative</th>\n",
              "      <td>102</td>\n",
              "      <td>490</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>positive</th>\n",
              "      <td>1</td>\n",
              "      <td>3114</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          negative  positive\n",
              "negative       102       490\n",
              "positive         1      3114"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7p_e7xQGatp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c52f8ca1-6572-44a4-89b4-5fa9b752e37a"
      },
      "source": [
        "%%time\n",
        "\n",
        "# Random Forest model on TF-IDF features\n",
        "\n",
        "# train model\n",
        "rf.fit(tv_train_features, train_sentiments)\n",
        "\n",
        "# predict on test data\n",
        "rf_tfidf_predictions = rf.predict(tv_test_features)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 25.9 s, sys: 33.8 ms, total: 25.9 s\n",
            "Wall time: 13.2 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ldv2CSIeGeMV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "outputId": "8a12d003-e440-4416-95d3-564074ac7d60"
      },
      "source": [
        "\n",
        "labels = ['negative', 'positive']\n",
        "print(classification_report(test_sentiments, rf_tfidf_predictions))\n",
        "pd.DataFrame(confusion_matrix(test_sentiments, rf_tfidf_predictions), index=labels, columns=labels)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.20      0.33       592\n",
            "           1       0.87      1.00      0.93      3115\n",
            "\n",
            "    accuracy                           0.87      3707\n",
            "   macro avg       0.92      0.60      0.63      3707\n",
            "weighted avg       0.88      0.87      0.83      3707\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>negative</th>\n",
              "      <th>positive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>negative</th>\n",
              "      <td>119</td>\n",
              "      <td>473</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>positive</th>\n",
              "      <td>4</td>\n",
              "      <td>3111</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          negative  positive\n",
              "negative       119       473\n",
              "positive         4      3111"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqkmbPIeGimI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gensim\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dropout, Activation, Dense\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoDWdasWMRdW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "le = LabelEncoder()\n",
        "# tokenize train reviews & encode train labels\n",
        "tokenized_train = [nltk.word_tokenize(text)\n",
        "                       for text in norm_train_reviews]\n",
        "y_train = le.fit_transform(train_sentiments)\n",
        "# tokenize test reviews & encode test labels\n",
        "tokenized_test = [nltk.word_tokenize(text)\n",
        "                       for text in norm_test_reviews]\n",
        "y_test = le.fit_transform(test_sentiments)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_8R4dMrMUp-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "8fdcdbf5-7cf3-4cbb-9f90-fc5feec30152"
      },
      "source": [
        "# print class label encoding map and encoded labels\n",
        "print('Sentiment class label map:', dict(zip(le.classes_, le.transform(le.classes_))))\n",
        "print('Sample test label transformation:\\n'+'-'*35,\n",
        "      '\\nActual Labels:', test_sentiments[:3], '\\nEncoded Labels:', y_test[:3])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentiment class label map: {0: 0, 1: 1}\n",
            "Sample test label transformation:\n",
            "----------------------------------- \n",
            "Actual Labels: [1 1 1] \n",
            "Encoded Labels: [1 1 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "621nK7_uMZFH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import logging\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPcOWQX_MdDG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d1b13477-e090-46ec-8df7-98ba39b09044"
      },
      "source": [
        "%%time\n",
        "# build word2vec model\n",
        "w2v_num_features = 300\n",
        "w2v_model = gensim.models.Word2Vec(tokenized_train, size=w2v_num_features, window=150,\n",
        "                                   min_count=10, workers=4, iter=5)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-09-18 07:06:54,419 : INFO : collecting all words and their counts\n",
            "2019-09-18 07:06:54,420 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "2019-09-18 07:06:54,568 : INFO : PROGRESS: at sentence #10000, processed 786775 words, keeping 29049 word types\n",
            "2019-09-18 07:06:54,639 : INFO : collected 36775 word types from a corpus of 1167142 raw words and 14825 sentences\n",
            "2019-09-18 07:06:54,640 : INFO : Loading a fresh vocabulary\n",
            "2019-09-18 07:06:54,875 : INFO : effective_min_count=10 retains 5110 unique words (13% of original 36775, drops 31665)\n",
            "2019-09-18 07:06:54,876 : INFO : effective_min_count=10 leaves 1107625 word corpus (94% of original 1167142, drops 59517)\n",
            "2019-09-18 07:06:54,900 : INFO : deleting the raw counts dictionary of 36775 items\n",
            "2019-09-18 07:06:54,903 : INFO : sample=0.001 downsamples 57 most-common words\n",
            "2019-09-18 07:06:54,904 : INFO : downsampling leaves estimated 790586 word corpus (71.4% of prior 1107625)\n",
            "2019-09-18 07:06:54,919 : INFO : estimated required memory for 5110 words and 300 dimensions: 14819000 bytes\n",
            "2019-09-18 07:06:54,920 : INFO : resetting layer weights\n",
            "2019-09-18 07:06:54,996 : INFO : training model with 4 workers on 5110 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=150\n",
            "2019-09-18 07:06:56,125 : INFO : EPOCH 1 - PROGRESS: at 16.71% examples, 113348 words/s, in_qsize 7, out_qsize 0\n",
            "2019-09-18 07:06:57,134 : INFO : EPOCH 1 - PROGRESS: at 34.35% examples, 125836 words/s, in_qsize 7, out_qsize 0\n",
            "2019-09-18 07:06:58,167 : INFO : EPOCH 1 - PROGRESS: at 51.43% examples, 127354 words/s, in_qsize 7, out_qsize 0\n",
            "2019-09-18 07:06:59,186 : INFO : EPOCH 1 - PROGRESS: at 66.46% examples, 125360 words/s, in_qsize 7, out_qsize 0\n",
            "2019-09-18 07:07:00,188 : INFO : EPOCH 1 - PROGRESS: at 83.44% examples, 127041 words/s, in_qsize 7, out_qsize 0\n",
            "2019-09-18 07:07:01,037 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-09-18 07:07:01,076 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-09-18 07:07:01,091 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-09-18 07:07:01,100 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-09-18 07:07:01,101 : INFO : EPOCH - 1 : training on 1167142 raw words (790266 effective words) took 6.1s, 129569 effective words/s\n",
            "2019-09-18 07:07:02,181 : INFO : EPOCH 2 - PROGRESS: at 16.61% examples, 118625 words/s, in_qsize 6, out_qsize 1\n",
            "2019-09-18 07:07:03,206 : INFO : EPOCH 2 - PROGRESS: at 34.35% examples, 127981 words/s, in_qsize 7, out_qsize 0\n",
            "2019-09-18 07:07:04,221 : INFO : EPOCH 2 - PROGRESS: at 49.64% examples, 125226 words/s, in_qsize 7, out_qsize 0\n",
            "2019-09-18 07:07:05,367 : INFO : EPOCH 2 - PROGRESS: at 67.32% examples, 124756 words/s, in_qsize 6, out_qsize 1\n",
            "2019-09-18 07:07:06,409 : INFO : EPOCH 2 - PROGRESS: at 84.26% examples, 125901 words/s, in_qsize 8, out_qsize 1\n",
            "2019-09-18 07:07:07,116 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-09-18 07:07:07,162 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-09-18 07:07:07,202 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-09-18 07:07:07,218 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-09-18 07:07:07,219 : INFO : EPOCH - 2 : training on 1167142 raw words (790638 effective words) took 6.1s, 129369 effective words/s\n",
            "2019-09-18 07:07:08,317 : INFO : EPOCH 3 - PROGRESS: at 16.61% examples, 116821 words/s, in_qsize 8, out_qsize 1\n",
            "2019-09-18 07:07:09,352 : INFO : EPOCH 3 - PROGRESS: at 34.35% examples, 126272 words/s, in_qsize 7, out_qsize 0\n",
            "2019-09-18 07:07:10,365 : INFO : EPOCH 3 - PROGRESS: at 50.61% examples, 126271 words/s, in_qsize 7, out_qsize 0\n",
            "2019-09-18 07:07:11,379 : INFO : EPOCH 3 - PROGRESS: at 66.46% examples, 126372 words/s, in_qsize 7, out_qsize 0\n",
            "2019-09-18 07:07:12,500 : INFO : EPOCH 3 - PROGRESS: at 84.26% examples, 126259 words/s, in_qsize 7, out_qsize 0\n",
            "2019-09-18 07:07:13,245 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-09-18 07:07:13,304 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-09-18 07:07:13,310 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-09-18 07:07:13,331 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-09-18 07:07:13,331 : INFO : EPOCH - 3 : training on 1167142 raw words (790809 effective words) took 6.1s, 129514 effective words/s\n",
            "2019-09-18 07:07:14,430 : INFO : EPOCH 4 - PROGRESS: at 16.71% examples, 116738 words/s, in_qsize 7, out_qsize 0\n",
            "2019-09-18 07:07:15,471 : INFO : EPOCH 4 - PROGRESS: at 34.35% examples, 125940 words/s, in_qsize 7, out_qsize 0\n",
            "2019-09-18 07:07:16,492 : INFO : EPOCH 4 - PROGRESS: at 50.61% examples, 125798 words/s, in_qsize 7, out_qsize 0\n",
            "2019-09-18 07:07:17,543 : INFO : EPOCH 4 - PROGRESS: at 66.46% examples, 124836 words/s, in_qsize 7, out_qsize 0\n",
            "2019-09-18 07:07:18,602 : INFO : EPOCH 4 - PROGRESS: at 84.24% examples, 126467 words/s, in_qsize 7, out_qsize 0\n",
            "2019-09-18 07:07:19,404 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-09-18 07:07:19,436 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-09-18 07:07:19,456 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-09-18 07:07:19,472 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-09-18 07:07:19,473 : INFO : EPOCH - 4 : training on 1167142 raw words (790599 effective words) took 6.1s, 128888 effective words/s\n",
            "2019-09-18 07:07:20,502 : INFO : EPOCH 5 - PROGRESS: at 15.78% examples, 118397 words/s, in_qsize 7, out_qsize 0\n",
            "2019-09-18 07:07:21,527 : INFO : EPOCH 5 - PROGRESS: at 32.63% examples, 124695 words/s, in_qsize 7, out_qsize 0\n",
            "2019-09-18 07:07:22,556 : INFO : EPOCH 5 - PROGRESS: at 49.75% examples, 126758 words/s, in_qsize 7, out_qsize 0\n",
            "2019-09-18 07:07:23,649 : INFO : EPOCH 5 - PROGRESS: at 66.46% examples, 125928 words/s, in_qsize 7, out_qsize 0\n",
            "2019-09-18 07:07:24,740 : INFO : EPOCH 5 - PROGRESS: at 84.24% examples, 126616 words/s, in_qsize 6, out_qsize 1\n",
            "2019-09-18 07:07:25,553 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-09-18 07:07:25,581 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-09-18 07:07:25,586 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-09-18 07:07:25,588 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-09-18 07:07:25,590 : INFO : EPOCH - 5 : training on 1167142 raw words (790410 effective words) took 6.1s, 129427 effective words/s\n",
            "2019-09-18 07:07:25,592 : INFO : training on a 5835710 raw words (3952722 effective words) took 30.6s, 129196 effective words/s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1min, sys: 110 ms, total: 1min\n",
            "Wall time: 31.2 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSgdilcRMmY5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def averaged_word2vec_vectorizer(corpus, model, num_features):\n",
        "    vocabulary = set(model.wv.index2word)\n",
        "    \n",
        "    def average_word_vectors(words, model, vocabulary, num_features):\n",
        "        feature_vector = np.zeros((num_features,), dtype=\"float64\")\n",
        "        nwords = 0.\n",
        "        \n",
        "        for word in words:\n",
        "            if word in vocabulary: \n",
        "                nwords = nwords + 1.\n",
        "                feature_vector = np.add(feature_vector, model.wv[word])\n",
        "        if nwords:\n",
        "            feature_vector = np.divide(feature_vector, nwords)\n",
        "\n",
        "        return feature_vector\n",
        "\n",
        "    features = [average_word_vectors(tokenized_sentence, model, vocabulary, num_features)\n",
        "                    for tokenized_sentence in corpus]\n",
        "    return np.array(features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDlwYH9BMnpZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "avg_wv_train_features = averaged_word2vec_vectorizer(corpus=tokenized_train, model=w2v_model,\n",
        "                                                     num_features=w2v_num_features)\n",
        "avg_wv_test_features = averaged_word2vec_vectorizer(corpus=tokenized_test, model=w2v_model,\n",
        "                                                    num_features=w2v_num_features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MCAhCtVM2Df",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fff04931-e563-41b7-efa5-237d6b4d6771"
      },
      "source": [
        "\n",
        "print('Word2Vec model:> Train features shape:', avg_wv_train_features.shape, ' Test features shape:', avg_wv_test_features.shape)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word2Vec model:> Train features shape: (14825, 300)  Test features shape: (3707, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSJ_bsQVM8Y6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def construct_deepnn_architecture(num_input_features):\n",
        "    dnn_model = Sequential()\n",
        "    dnn_model.add(Dense(512, input_shape=(num_input_features,)))\n",
        "    dnn_model.add(Activation('relu'))\n",
        "    dnn_model.add(Dropout(0.2))\n",
        "    \n",
        "    dnn_model.add(Dense(256))\n",
        "    dnn_model.add(Activation('relu'))\n",
        "    dnn_model.add(Dropout(0.2))\n",
        "    \n",
        "    dnn_model.add(Dense(256))\n",
        "    dnn_model.add(Activation('relu'))\n",
        "    dnn_model.add(Dropout(0.2))\n",
        "    \n",
        "    dnn_model.add(Dense(1))\n",
        "    dnn_model.add(Activation('sigmoid'))\n",
        "\n",
        "    dnn_model.compile(loss='binary_crossentropy', optimizer='adam',                 \n",
        "                      metrics=['accuracy'])\n",
        "    return dnn_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ViFfvOVNACW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "c2b4cd44-7a97-43bc-f557-5176074184a1"
      },
      "source": [
        "w2v_dnn = construct_deepnn_architecture(num_input_features=w2v_num_features)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-18 07:09:10,220 : WARNING : From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-18 07:09:10,391 : WARNING : From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIb30iGiNEXQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "de0d8737-3d91-4128-f884-8d778224ebb7"
      },
      "source": [
        "\n",
        "w2v_dnn.summary()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 512)               154112    \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 257       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 351,489\n",
            "Trainable params: 351,489\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nngjr-6tNJuP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "f5b687de-d6b8-42e2-a3b4-93e7ded31d58"
      },
      "source": [
        "batch_size = 100\n",
        "w2v_dnn.fit(avg_wv_train_features, y_train, epochs=10, batch_size=batch_size, \n",
        "            shuffle=True, validation_split=0.1, verbose=1)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 13342 samples, validate on 1483 samples\n",
            "Epoch 1/10\n",
            "13342/13342 [==============================] - 2s 124us/sample - loss: 0.3232 - acc: 0.8620 - val_loss: 0.2985 - val_acc: 0.8759\n",
            "Epoch 2/10\n",
            "13342/13342 [==============================] - 1s 90us/sample - loss: 0.2944 - acc: 0.8728 - val_loss: 0.2971 - val_acc: 0.8726\n",
            "Epoch 3/10\n",
            "13342/13342 [==============================] - 1s 88us/sample - loss: 0.2858 - acc: 0.8763 - val_loss: 0.2940 - val_acc: 0.8800\n",
            "Epoch 4/10\n",
            "13342/13342 [==============================] - 1s 90us/sample - loss: 0.2831 - acc: 0.8790 - val_loss: 0.2890 - val_acc: 0.8786\n",
            "Epoch 5/10\n",
            "13342/13342 [==============================] - 1s 89us/sample - loss: 0.2756 - acc: 0.8814 - val_loss: 0.2873 - val_acc: 0.8759\n",
            "Epoch 6/10\n",
            "13342/13342 [==============================] - 1s 92us/sample - loss: 0.2678 - acc: 0.8834 - val_loss: 0.2829 - val_acc: 0.8813\n",
            "Epoch 7/10\n",
            "13342/13342 [==============================] - 1s 87us/sample - loss: 0.2660 - acc: 0.8839 - val_loss: 0.2859 - val_acc: 0.8806\n",
            "Epoch 8/10\n",
            "13342/13342 [==============================] - 1s 93us/sample - loss: 0.2597 - acc: 0.8879 - val_loss: 0.2857 - val_acc: 0.8780\n",
            "Epoch 9/10\n",
            "13342/13342 [==============================] - 1s 93us/sample - loss: 0.2562 - acc: 0.8891 - val_loss: 0.2879 - val_acc: 0.8780\n",
            "Epoch 10/10\n",
            "13342/13342 [==============================] - 1s 92us/sample - loss: 0.2528 - acc: 0.8912 - val_loss: 0.2855 - val_acc: 0.8773\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f54856ece80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3E31pPBNRxP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "2dea8b36-4d32-453b-f349-9a9fc36e9fc8"
      },
      "source": [
        "y_pred = w2v_dnn.predict_classes(avg_wv_test_features)\n",
        "predictions = le.inverse_transform(y_pred)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:273: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5FSlUYCNUpO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "outputId": "1a354768-dd91-4309-fce1-d6cd084e6d10"
      },
      "source": [
        "\n",
        "labels = ['negative', 'positive']\n",
        "print(classification_report(test_sentiments, predictions))\n",
        "pd.DataFrame(confusion_matrix(test_sentiments, predictions), index=labels, columns=labels)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.41      0.52       592\n",
            "           1       0.90      0.97      0.93      3115\n",
            "\n",
            "    accuracy                           0.88      3707\n",
            "   macro avg       0.80      0.69      0.73      3707\n",
            "weighted avg       0.87      0.88      0.87      3707\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>negative</th>\n",
              "      <th>positive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>negative</th>\n",
              "      <td>245</td>\n",
              "      <td>347</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>positive</th>\n",
              "      <td>103</td>\n",
              "      <td>3012</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          negative  positive\n",
              "negative       245       347\n",
              "positive       103      3012"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    }
  ]
}